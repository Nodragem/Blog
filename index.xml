<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>NODRAGEM GAMES on NODRAGEM GAMES</title>
    <link>https://nodragem.github.io/Blog/</link>
    <description>Recent content in NODRAGEM GAMES on NODRAGEM GAMES</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016 Geoffrey MÃ©gardon</copyright>
    <lastBuildDate>Thu, 03 Sep 2020 18:03:01 +0100</lastBuildDate>
    <atom:link href="https://nodragem.github.io/Blog/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Unity: Controlling the Color of Parts of a Texture with a Color Mask</title>
      <link>https://nodragem.github.io/Blog/post/gamedev/03_shader_graph_change_color/</link>
      <pubDate>Thu, 03 Sep 2020 18:03:01 +0100</pubDate>
      
      <guid>https://nodragem.github.io/Blog/post/gamedev/03_shader_graph_change_color/</guid>
      <description>&lt;h2 id=&#34;what-you-will-learn&#34;&gt;What you will learn&lt;/h2&gt;
&lt;p&gt;In this tutorial you will learn how to make a shader with the Shader Graph so you can modify the color of part of a texture like this:
&lt;img src=&#34;./img/demo-color-change.gif&#34; alt=&#34;demo-color-change&#34;&gt;&lt;/p&gt;
&lt;p&gt;I used this methods to control the colors of the plane and of the bombs&amp;rsquo; fin in my recent game &lt;a href=&#34;https://gamejolt.com/games/prabbits-dogfights/433068&#34;&gt;The Prabbits: Happy Dogfights!&lt;/a&gt; Here you see myself playing around with the newly colored bomb :)&lt;/p&gt;
&lt;iframe width=&#34;800&#34; height=&#34;400&#34; src=&#34;https://www.youtube.com/embed/5-uObavYhvw&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;h2 id=&#34;color-mask-with-unity-shader-graph&#34;&gt;Color Mask with Unity Shader Graph&lt;/h2&gt;
&lt;p&gt;When your object is made of multiple materials, it is easy to change the colour of its parts. However, most of the time, we try to keep the number of materials on screen low for performance reason. In that case the color information is within a texture and if you want to offer &lt;strong&gt;several colors&lt;/strong&gt; of a same object, you might be tempted to make &lt;strong&gt;several textures&lt;/strong&gt; altogether.&lt;/p&gt;
&lt;p&gt;If you plan to support few colors, it is totally fine, but what if you want the player to be able to pick &lt;strong&gt;any color&lt;/strong&gt;?&lt;/p&gt;
&lt;p&gt;As the colour information of my bomb (or plane) is contained in a texture, we need to solve the problem with a custom shader, and it is actually easier than what I thought it would be to implement, thanks to &lt;strong&gt;Unity Graph Shader&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;steps&#34;&gt;Steps:&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;In your 2D software make sure that the texture is in black and white where you want the color to be applied&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Before:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;img/death_bomb_texture.png&#34; alt=&#34;death_bomb_texture&#34;&gt;&lt;/p&gt;
&lt;p&gt;After:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;img/bomb_color_texture.png&#34; alt=&#34;bomb_color_texture&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;In your 2D software, create a new image (or layer) with a black background and paint in white where the color should be applied:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;img/ColorMask.png&#34; alt=&#34;ColorMask&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;
&lt;p&gt;In Unity&amp;rsquo;s Project panel, right click in one of your asset folders and select &lt;code&gt;Create &amp;gt; Shader &amp;gt; PBR Graph&lt;/code&gt;, then double-click on the newly created asset. That should open up the Graph Shader.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cliking on the + button, create the following exposed variables:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;img/Unity_2020-09-03_17-20-58.png&#34; alt=&#34;Unity_2020-09-03_17-20-58&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;Create a Sample Texture 2D node and attach it to the ColorTexture (i.e. hitting &amp;ldquo;spacebar&amp;rdquo;, start writing &amp;ldquo;Sample Text&amp;hellip;&amp;rdquo; and select the node).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;img/Unity_2020-09-03_17-23-25.png&#34; alt=&#34;Unity_2020-09-03_17-23-25&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;
&lt;p&gt;Create a Sample Texture 2D node and attach it to the ColorMask,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a Multiply node and attach the DecorationColor node and Sample Texture 2D to it,&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;img/Unity_2020-09-03_17-23-15.png&#34; alt=&#34;Unity_2020-09-03_17-23-15&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;8&#34;&gt;
&lt;li&gt;Combine the two branches with a Add node and connect the result to the Albedo channel of the PBR Master node:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;img/Unity_2020-09-03_17-24-36.png&#34; alt=&#34;Unity_2020-09-03_17-24-36&#34;&gt;&lt;/p&gt;
&lt;p&gt;And you are done!&lt;/p&gt;
&lt;ol start=&#34;9&#34;&gt;
&lt;li&gt;&lt;em&gt;[Optional]&lt;/em&gt; You can also add a Smoothness and Roughness texture to the PBR Master node as I did below (note that I stored the Smoothness information in the alpha channel of my texture):&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;img/Unity_2020-09-03_17-25-27.png&#34; alt=&#34;Unity_2020-09-03_17-25-27&#34;&gt;&lt;/p&gt;
&lt;p&gt;So, that&amp;rsquo;s it! You should be able to control the color of your object using the DecorationColor variable!&lt;/p&gt;
&lt;p&gt;In a script, assuming that your color is stored in &lt;code&gt;m_PlayerColor&lt;/code&gt;, you will need to do:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-c#&#34; data-lang=&#34;c#&#34;&gt;&lt;span style=&#34;color:#815ba4&#34;&gt;this&lt;/span&gt;.gameObject.GetComponent&amp;lt;Renderer&amp;gt;().material.SetColor(&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#34;_DecorationColor&amp;#34;&lt;/span&gt;, m_PlayerColor);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;I hope this helps you in your game development, don&amp;rsquo;t hesitate to share other methods in the comment below ðŸ™‚&lt;/p&gt;
&lt;p&gt;See you around!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Baking PBR Materials to Textures from Blender to Unity</title>
      <link>https://nodragem.github.io/Blog/post/gamedev/02_pbr_blender_to_unity/</link>
      <pubDate>Fri, 12 Jun 2020 10:50:01 +0100</pubDate>
      
      <guid>https://nodragem.github.io/Blog/post/gamedev/02_pbr_blender_to_unity/</guid>
      <description>&lt;h2 id=&#34;multiple-materials-to-baked-textures&#34;&gt;Multiple Materials to Baked Textures&lt;/h2&gt;
&lt;p&gt;Until now the planes in Happy Dogfights were made of multiple materials so that it was easy to change the colour of the plane in Unity. When a player selects a colour, I just modify the colour of the material used for the body of the plane. It also made sense when working in Blender to have a different material for the tyres, the body, the engine, etc, so that I could control their metalness, roughness, and colour independently.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;img/4color.gif&#34; alt=&#34;4color&#34;&gt;&lt;/p&gt;
&lt;p&gt;However, this method has its limitations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;it is not optimal in terms of real-time rendering&lt;/li&gt;
&lt;li&gt;I could not apply surface shaders VFX, like flame or electricity effects, on the plane.&lt;/li&gt;
&lt;li&gt;the PBR parameters (e.g. colour, roughness, metalness, emission) were not imported by Unity, I had to enter them manually&lt;/li&gt;
&lt;li&gt;I could not use complex procedural materials in Blender (as I could not export them)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A better but more involved method is to unwrap the plane&amp;rsquo;s UV and bake all the materials into PBR textures so that the plane only use one material.&lt;/p&gt;
&lt;p&gt;This way I could benefit from:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;better performance using a unique material for the plane&lt;/li&gt;
&lt;li&gt;an automatic import  of the PBR parameters (colour, roughness, etc) as they are saved in a texture&lt;/li&gt;
&lt;li&gt;surface shader VFX as the UVs are unwrapped&lt;/li&gt;
&lt;li&gt;I can work with multiple and procedural materials in Blender&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But for that to happen, I needed to find a way to bake the materials!&lt;/p&gt;
&lt;p&gt;In this tutorial, I am covering that problem: how to bake multiple procedural materials into textures in Blender, in a way that is compatible with Unity. In a future tutorial, I will cover how to change the colour of the plane when its colour information is stored in a texture.&lt;/p&gt;
&lt;h2 id=&#34;step-by-step-tutorial&#34;&gt;Step by Step Tutorial&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Get the Free and Open Source add-on of Daniel Enger.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Go to the Github repository at &lt;a href=&#34;https://github.com/danielenger/Principled-Baker:&#34;&gt;https://github.com/danielenger/Principled-Baker:&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;img/image-20200606152319418.png&#34; alt=&#34;image-20200606152319418&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Download the repository as a zip-file.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install the Add-on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;In Blender, go in  &lt;code&gt;Edit &amp;gt; Preferences &amp;gt; Add-ons&lt;/code&gt;, click &lt;code&gt;Install...&lt;/code&gt;,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;find the zip file you just downloaded, click &lt;code&gt;Install Add-on&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Find the Add-on:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;img/image-20200606154340911.png&#34; alt=&#34;image-20200606154340911&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Go to the &lt;code&gt;Shading tab&lt;/code&gt;, hover the mouse over the Shader Editor, and press &lt;kbd&gt;N&lt;/kbd&gt; ,&lt;/li&gt;
&lt;li&gt;Click on the tab &lt;code&gt;Principled Baker&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use the Add-on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Select the object to baked&lt;img src=&#34;img/image-20200606154214947.png&#34; alt=&#34;image-20200606154214947&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Deselect &lt;code&gt;Autodetect&lt;/code&gt;, tick &lt;code&gt;Color&lt;/code&gt;, &lt;code&gt;Metallic&lt;/code&gt; and &lt;code&gt;Roughness&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;img/image-20200606162743678.png&#34; alt=&#34;image-20200606162743678&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In Additional Bake Types, tick &lt;code&gt;Glossiness&lt;/code&gt;, this is what Unity calls Smoothness (i.e. 1 - roughness)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Scroll down and find &lt;code&gt;Combine Channel&lt;/code&gt;, and click &lt;code&gt;+&lt;/code&gt; (in Unity, the metal map includes the roughness map as alpha channel)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set the Channels as follow:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;img/image-20200606163923937.png&#34; alt=&#34;image-20200606163923937&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Scroll up and click bake!&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now if you export the plane as FBX without materials and import it in Unity. Create a material where you use the colour texture as a base map, and the combined texture as a metallic map.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;img/image-20200612122542943.png&#34; alt=&#34;image-20200612122542943&#34;&gt;&lt;/p&gt;
&lt;p&gt;You should get your object with the materials looking as they do in Blender.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;img/image-20200606185940453.png&#34; alt=&#34;image-20200606185940453&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h2&gt;
&lt;p&gt;Now that the different colours of the plane are contained in a texture, it will be more complicated to change its colour ðŸ˜… but worry not, the problem can be solved with a custom shader, and it is easy to implement with the Graph Shader. See you around!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building an AI for my game - Part 1: Breaking down the problem</title>
      <link>https://nodragem.github.io/Blog/post/gamedev/01_ia_blogpost1/</link>
      <pubDate>Sat, 11 Jan 2020 13:47:08 +0100</pubDate>
      
      <guid>https://nodragem.github.io/Blog/post/gamedev/01_ia_blogpost1/</guid>
      <description>&lt;p&gt;I realised that my game needed a single player mode so that players can give it a try easily, or can play the game until they get some friends to come over (or to meet them online). So here we go, I am programming an AI for the prabbits; that I called the prab-bot!&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  
NOTE: I have a Neuroscience background, but I am far from being an expert in AI!

&lt;/div&gt;

&lt;h2 id=&#34;transforming-inputs-into-meaningful-actions&#34;&gt;Transforming inputs into meaningful actions&lt;/h2&gt;
&lt;p&gt;A brain, or an AI, is essentially an entity that transforms sensory information (i.e. inputs) into motor commands (i.e. outputs). To be intelligent, its sensory to motor transformation should be optimising relevant needs or goals (e.g. surviving, reproducing, etc).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;img/Plot_Intro.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;In research, there is a distinction between making a decision, selecting an action and controlling an action.&lt;/p&gt;
&lt;p&gt;Here a real-life example: you feel thirst (sensory information) and decide you need to drink water as soon as possible (i.e. prioritisation of needs). The action selection comes afterwards: you could stand, take a glass and fill it with water, you could ask your partner to bring you water, or you could simply reach for the glass filled with water in front of you. 
Once you decided that to reach for the glass is the best action to take comes the action control. Action control is how the goal (glass position in space) is transformed into contractions of your arm muscle so that your hand reaches it and grab it.&lt;/p&gt;
&lt;p&gt;In some cases, as in deciding where to look at, the sensory information, decision making, action selection and action control are all really entangled and there might be several pathways in competitions; but for our game, we will keep thing simple.&lt;/p&gt;
&lt;p&gt;In our game, we (as a brain designer) can confer the prab-bots multiple &lt;strong&gt;sensory inputs&lt;/strong&gt; and multiple &lt;strong&gt;motor commands&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;img/Plot1.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;side-note&#34;&gt;
  &lt;button type=&#34;button&#34; class=&#34;side-collapsible&#34;&gt; Open Note&lt;/button&gt;
  &lt;div class=&#34;side-content&#34;&gt;
    
We could probably make the prab-bots more human if you designed their sensors so that they cannot pay attention to all of them at the same time. For instance, a human will mainly look at one thing at a time on the screen; but let&#39;s keep thing simple for now.

   &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;To design an AI is about transforming the &lt;strong&gt;sensory inputs&lt;/strong&gt; into &lt;strong&gt;motor commands&lt;/strong&gt; so that the prab-bots achieve some goal; that we will call &lt;strong&gt;high-level goals&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;side-note&#34;&gt;
  &lt;button type=&#34;button&#34; class=&#34;side-collapsible&#34;&gt; Open Note&lt;/button&gt;
  &lt;div class=&#34;side-content&#34;&gt;
    
In Machine Learning, one could connect the **sensory inputs** to the input neurons of a deep neural network, and connect the output neurons to the **motor commands**. The *high-level goals* I am speaking about would be used to punish or reward the network during its training. We are not going to use machine learning though; we are going to design the AI ourselves.

   &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;To make decisions, you need &lt;strong&gt;high-level goals&lt;/strong&gt; to fulfill, which can be as simple as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;be the last plane flying
&lt;ul&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Health must be kept always greater than 0&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Destroy other&amp;rsquo;s plane&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;img/Plot2.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;side-note&#34;&gt;
  &lt;button type=&#34;button&#34; class=&#34;side-collapsible&#34;&gt; Open Note&lt;/button&gt;
  &lt;div class=&#34;side-content&#34;&gt;
    
To optimise the above needs may not &#34;mathematically&#34; lead you to win the competition; to win the competition you need to eliminate whoever is ahead with a bomb, so they lose their advantage. However, most &#34;human beginners&#34; will just focus on destroying other&#39;s planes.

   &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Based on the &lt;strong&gt;high-level goals&lt;/strong&gt; and on the &lt;em&gt;sensory inputs&lt;/em&gt;, we can design &lt;strong&gt;low-level needs&lt;/strong&gt; and &lt;em&gt;prioritisation rules&lt;/em&gt;. These &lt;strong&gt;low-level needs&lt;/strong&gt; are a step closer to actual actions, they can be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;get more health&lt;/li&gt;
&lt;li&gt;get more bullets&lt;/li&gt;
&lt;li&gt;get more bomb&lt;/li&gt;
&lt;li&gt;avoid something&lt;/li&gt;
&lt;li&gt;try to attack someone&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;strong&gt;high-level goals&lt;/strong&gt; will also define the sensitivity rules that link &lt;em&gt;sensory inputs&lt;/em&gt; and &lt;strong&gt;low-level needs&lt;/strong&gt;. For instance: a decrease of &lt;em&gt;&amp;ldquo;own health&amp;rdquo;&lt;/em&gt; will increase the need &lt;em&gt;&amp;ldquo;get more health&amp;rdquo;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;img/Plot3.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;In practice, some of these &lt;strong&gt;low-level needs&lt;/strong&gt; can translate directly into a simple action. For instance, if our prab-bot decided to prioritise the low-level need &lt;em&gt;&amp;ldquo;get more health&amp;rdquo;&lt;/em&gt;, the next question is which &lt;em&gt;&amp;ldquo;heart&amp;rdquo;&lt;/em&gt; to go to? this step is the &lt;strong&gt;target selection&lt;/strong&gt;: based on its sensory-motor information, the prab-bot will select which heart is the most beneficial to go to; this is the final step before an actual movement can start. As our prab-bot has access to its position and the hearts&amp;rsquo; position, the target selection can be as simple as finding the closest heart. For a human-like behaviour, you&amp;rsquo;d need to consider that a human doesn&amp;rsquo;t always pay attention to everything that happens on the screen, and it is a bit more complicated.&lt;/p&gt;
&lt;p&gt;Now that we have a target to reach, the final step is the &lt;strong&gt;action control&lt;/strong&gt;. This is about transforming the action &lt;em&gt;&amp;ldquo;go to target&amp;rdquo;&lt;/em&gt; into motor commands (i.e. movements) that achieve the goal of that action. For instance, to get a heart, the &lt;strong&gt;action controller&lt;/strong&gt; needs to use the &lt;strong&gt;sensory inputs&lt;/strong&gt; (e.g. the plane direction, the heart position) and &lt;strong&gt;motor commands&lt;/strong&gt; (i.e. rotate the plane CCW/ACW) in order to align the plane with the heart position, then the action controller will wait until the plane reaches it. If there is no obstacle, these rules should do great.&lt;/p&gt;
&lt;p&gt;In description, the low-level need &lt;em&gt;&amp;ldquo;get more life&amp;rdquo;&lt;/em&gt; will lead to the target selection &lt;em&gt;&amp;ldquo;selecting a heart&amp;rdquo;&lt;/em&gt; and then execute the action &lt;em&gt;&amp;ldquo;go to target&amp;rdquo;&lt;/em&gt; using the motor commands &lt;em&gt;&amp;ldquo;rotate ACW/CW&amp;rdquo;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;img/Plot5.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Even if the above already sounds a bit complicated, it was in fact a simple case :) ! Indeed, some &lt;strong&gt;low-level needs&lt;/strong&gt; such as &lt;em&gt;get more bullets&lt;/em&gt; can lead to a series of simple actions and small decisions:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#815ba4&#34;&gt;if&lt;/span&gt; (enough money):
   execute the action &lt;span style=&#34;color:#48b685&#34;&gt;&amp;#34;buy bullets&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#776e71&#34;&gt;# which triggers the motor command &amp;#34;buy bullet&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#815ba4&#34;&gt;else&lt;/span&gt;:
  &lt;span style=&#34;color:#f99b15&#34;&gt;1.&lt;/span&gt; prioritise need &lt;span style=&#34;color:#48b685&#34;&gt;&amp;#34;get more coins&amp;#34;&lt;/span&gt;:
     &lt;span style=&#34;color:#f99b15&#34;&gt;1.&lt;/span&gt; target selection &lt;span style=&#34;color:#48b685&#34;&gt;&amp;#34;selection of a coin&amp;#34;&lt;/span&gt;, 
     &lt;span style=&#34;color:#f99b15&#34;&gt;2.&lt;/span&gt; execute action &lt;span style=&#34;color:#48b685&#34;&gt;&amp;#34;go to target&amp;#34;&lt;/span&gt; 
     &lt;span style=&#34;color:#f99b15&#34;&gt;3.&lt;/span&gt; repeat until enough coins
  &lt;span style=&#34;color:#f99b15&#34;&gt;2.&lt;/span&gt; prioritise need &lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;buy bullet&amp;#39;&lt;/span&gt;:
     &lt;span style=&#34;color:#f99b15&#34;&gt;1.&lt;/span&gt; execute the action &lt;span style=&#34;color:#48b685&#34;&gt;&amp;#34;buy bullets&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#776e71&#34;&gt;# which triggers the motor command &amp;#34;buy bullet&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Furthermore, although the brain mostly executes one action at a time (multi-tasking is complicated), it can execute actions that account for multiple &lt;strong&gt;low-level needs&lt;/strong&gt; at the same time, or execute the current action in a way that prepares us to the second action. For instance:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;you can reach for a heart while avoiding a bomb: you are executing an action that optimises two constraints (an attractor and a repeller)&lt;/li&gt;
&lt;li&gt;you can get to a heart while approaching it in a direction that aligns you with a coin, so that you ease  the execution of your next action (collecting coins)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Finally, to add to the complexity, the environment may change (i.e. there is no heart anymore on the map) while you are executing your action. This will change the ranking of your &lt;strong&gt;low-level needs&lt;/strong&gt; and make the current action irrelevant.&lt;/p&gt;
&lt;p&gt;I think this is it for our introduction to IA :) we had a really good think on how to model the decision making that transforms the sensory input of our prab-bots into actions that are relevant for a high-level goal (i.e. to win the round). The framework I try to put together may not be perfect but it is a good start in putting words on things and encapsulating our general AI problem into smaller parts. Our next tutorial will be on creating the action controllers. See you next time!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Release Notes: Happy Dogfight 0.2.0</title>
      <link>https://nodragem.github.io/Blog/post/gamedev/notes_happy-dogfight_020/</link>
      <pubDate>Thu, 12 Dec 2019 21:27:08 +0100</pubDate>
      
      <guid>https://nodragem.github.io/Blog/post/gamedev/notes_happy-dogfight_020/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  
Major Update!

&lt;/div&gt;

&lt;p&gt;Finally updating the demo of my next game, just in time for you to enjoy with some friends during the festive season :) Hope you like it! A lot of love and time has gone into it. In description, it is much more fun and less buggy :) with a new level to unlock. But for those who wants to know more, I prepared a detailed changelog you can read below.&lt;/p&gt;
&lt;h2 id=&#34;a-new-level-and-a-newsletter&#34;&gt;A New Level and a Newsletter&lt;/h2&gt;
&lt;p&gt;I wanted to make a valuable gift to players who may like the game and want to join the newsletter I am planning to start (already part of my new year&amp;rsquo;s resolutions). So I developed an additional level especially for the occasion!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/notes_happydogfights_020/demo-level4-2.gif&#34; alt=&#34;demo-level4-2&#34;&gt;&lt;/p&gt;
&lt;p&gt;It is inspired by ironworkers and the giant crane hook they use to raise beams of steel up to the sky. Watch for the iron ball as it will be deadly.
I also designed an in-game form for players to join the newsletter. 
Hopefully, I will be speaking to you soon about the development of the game and my new gameplay and game mode ideas :) !&lt;/p&gt;
&lt;h2 id=&#34;change-to-the-gameplay&#34;&gt;Change to the Gameplay&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/notes_happydogfights_020/newbomb-demo.gif&#34; alt=&#34;newbomb-demo&#34;&gt;&lt;/p&gt;
&lt;p&gt;The Bomb does not eliminate a player for the whole tournament any more. This was judged too punitive; now, a bomb will eliminate a player for the next round only. Hence if you only play at two players, the player who used the bomb will win two rounds at once.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/notes_happydogfights_020/demo-bomb-small.gif&#34; alt=&#34;demo-bomb-small&#34;&gt;&lt;/p&gt;
&lt;p&gt;The radius of the Bomb is now shown on the screen with a red semi-transparent circle.
The bomb will explode at the end of its timer (instead of simply disappearing); when the time comes close, the red circle will flicker.&lt;/p&gt;
&lt;p&gt;I also reduced the number of hearts and increased the time before they respawn: there were too many hearts, that made the dogfights too long.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/notes_happydogfights_020/control-scheme.gif&#34; alt=&#34;control-scheme&#34;&gt;&lt;/p&gt;
&lt;p&gt;Finally the controls have changed a bit, it is now left to turn the plane anti-clockwise and right to turn the plane clockwise. The player can now control the speed of the plane with the vertical axis of the second thumbstick.&lt;/p&gt;
&lt;h2 id=&#34;new-local-multiplayer&#34;&gt;New Local Multiplayer&lt;/h2&gt;
&lt;p&gt;You can play locally without being connected to the internet! Sounds quite normal, but before this release the game needed to connect to internet :) !&lt;/p&gt;
&lt;p&gt;Although that&amp;rsquo;s not a new feature, note that you can play at two on the same keyboard!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/notes_happydogfights_020/image-20191208193326587.png&#34; alt=&#34;image-20191208193326587&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;updated-online-multiplayer&#34;&gt;Updated Online Multiplayer&lt;/h2&gt;
&lt;p&gt;The online multiplayer is now much closer to what exists elsewhere, with a lobby and rooms. It is still &lt;strong&gt;experimental&lt;/strong&gt;; as I am using a free server for this free demo, &lt;em&gt;&lt;strong&gt;only 20 concurrent clients can play at the same time&lt;/strong&gt;&lt;/em&gt;. Here what&amp;rsquo;s new:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;new Lobby and Rooms system&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;create a room with its unique name for your friends to find you easily&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/notes_happydogfights_020/demo-createroom.gif&#34; alt=&#34;demo-createroom&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;use the search button to find the room of your friend&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/notes_happydogfights_020/demo-lobby.gif&#34; alt=&#34;demo-lobby&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Master client needs to wait for other clients&amp;rsquo; players to be ready&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;the game still allows several players to play from the same machine&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;graphic-updates-and-readability&#34;&gt;Graphic Updates and Readability&lt;/h2&gt;
&lt;p&gt;I realised that some players did not always follow what was going on during a tournament. For instance, some players did not know who was currently leading the tournament (and hence who should be hunted). I tried to make the game more readable.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Level 1 and Level 2 were redecorated (see below)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;a crown was added on the head of the Prabbit who won the most rounds:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/notes_happydogfights_020/Unity_A2VkcE6cq4.png&#34; alt=&#34;Unity_A2VkcE6cq4&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;an arrow pointing forward was added to help the player aim when shooting&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;players can test which slot they are in the player list by pressing START:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/notes_happydogfights_020/pressSTART.gif&#34; alt=&#34;pressSTART&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;textual announcement of who is not playing next round&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;planes will emit smoke based on their remaining life (white for 50% life, black for 1% life)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;more readable leaderboard, the text &amp;ldquo;1/5 wins&amp;rdquo; was replaced with a row of stars that is easier to read&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/notes_happydogfights_020/demo-leaderboard2.gif&#34; alt=&#34;demo-leaderboard2&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;the star animation makes the winner more visible&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&amp;ldquo;Out Next Round&amp;rdquo; is displayed in the leaderboard when players are eliminated for the next round&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ui-improvement&#34;&gt;UI improvement&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/notes_happydogfights_020/demo-fume2menu.gif&#34; alt=&#34;demo-fume2menu&#34;&gt;&lt;/p&gt;
&lt;p&gt;A new in-game menu allows players to go back to the level selection/lobby or see the controls.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/notes_happydogfights_020/controls-demo.gif&#34; alt=&#34;controls-demo&#34;&gt;&lt;/p&gt;
&lt;p&gt;A new help panel was added to familiarise players with the control schemes and rules.&lt;/p&gt;
&lt;h2 id=&#34;bug-corrections&#34;&gt;Bug corrections&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ghost plane: after a plane was destroyed, its collision box could still be active and destroy your plane&lt;/li&gt;
&lt;li&gt;sometimes, to kill the last player with a bomb would make the player win the tournament&lt;/li&gt;
&lt;li&gt;many more&amp;hellip; in a few words, the game should be more stable now!&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;download&#34;&gt;Download&lt;/h2&gt;
&lt;p&gt;You can grab the demo here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://nodragem.github.io/Blog/Blog/project/released-happy-dogfight/&#34;&gt;Free Early Access of Happy Dogfigths 0.2.0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Or directly from here:&lt;/p&gt;
&lt;iframe src=&#34;https://widgets.gamejolt.com/package/v1?key=Z8cUgjHM&#34; frameborder=&#34;0&#34; width=&#34;500&#34; height=&#34;145&#34;&gt;&lt;/iframe&gt;
&lt;p&gt;Don&amp;rsquo;t hesitate to leave your feedback!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Prabbits: Happy Dogfights!</title>
      <link>https://nodragem.github.io/Blog/project/released-happy-dogfight/</link>
      <pubDate>Sun, 08 Dec 2019 14:51:57 +0100</pubDate>
      
      <guid>https://nodragem.github.io/Blog/project/released-happy-dogfight/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/level4-demo.gif&#34; alt=&#34;wrong link&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;download&#34;&gt;Download&lt;/h2&gt;
&lt;iframe src=&#34;https://widgets.gamejolt.com/package/v1?key=Z8cUgjHM&#34; frameborder=&#34;0&#34; width=&#34;500&#34; height=&#34;145&#34;&gt;&lt;/iframe&gt;
&lt;h2 id=&#34;follow-us&#34;&gt;Follow us:&lt;/h2&gt;
&lt;p&gt;Watch couchplay sessions with my friends on &lt;strong&gt;&lt;a href=&#34;https://www.youtube.com/channel/UCwNOb0bisGEMFwtPWBtEW-g&#34;&gt;Youtube&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Come play with us and get the latest news on &lt;strong&gt;&lt;a href=&#34;https://discord.gg/TCEKa4D&#34;&gt;Discord&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;You can also follow the development on &lt;strong&gt;&lt;a href=&#34;https://twitter.com/Nodragem&#34;&gt;Twitter&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;release-notes&#34;&gt;Release Notes&lt;/h2&gt;
&lt;p&gt;You can find the detail of the last updates here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://nodragem.github.io/Blog/Blog/post/gamedev/notes_happy-dogfight_020/&#34;&gt;What&amp;rsquo;s New in the Free Version of Happy Dogfigths 0.2.0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;Happy Dogfight is a multiplayer 2D dogfight game to play with friends (2-4 players) on a couch or online.&lt;/p&gt;
&lt;p&gt;You are a prabbit (mix of rabbit and parrot) who wants to prove that they are the best pilot in their tribe.&lt;/p&gt;
&lt;p&gt;You will dive into explosive dogfights, blast your way to the podium in fast-paced rounds, and bomb your friends to kick them out the next round.&lt;/p&gt;
&lt;p&gt;Can you blow all your friends up at once to claim a &lt;strong&gt;smashing victory&lt;/strong&gt;?&lt;/p&gt;
&lt;h2 id=&#34;credits&#34;&gt;Credits&lt;/h2&gt;
&lt;p&gt;Software used:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://unity.com/&#34;&gt;&lt;strong&gt;Unity&lt;/strong&gt;&lt;/a&gt; (Game Engine):&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.blender.org/&#34;&gt;&lt;strong&gt;Blender&lt;/strong&gt;&lt;/a&gt; (3D Graphics/Painting)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://krita.org/en/&#34;&gt;&lt;strong&gt;Krita&lt;/strong&gt;&lt;/a&gt; (2D Graphics/Painting)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.drpetter.se/project_sfxr.html&#34;&gt;&lt;strong&gt;sfxr&lt;/strong&gt;&lt;/a&gt;/&lt;a href=&#34;https://www.bfxr.net&#34;&gt;&lt;strong&gt;bfxr&lt;/strong&gt;&lt;/a&gt; (Sound FX)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://labbed.net/software/labchirp/&#34;&gt;&lt;strong&gt;LabChirp&lt;/strong&gt;&lt;/a&gt; (Sound FX)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.audacityteam.org/&#34;&gt;&lt;strong&gt;Audacity&lt;/strong&gt;&lt;/a&gt; (Voice Recording and Editing)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lmms.io/&#34;&gt;&lt;strong&gt;LMMS&lt;/strong&gt;&lt;/a&gt; (Music)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Bubble Troop</title>
      <link>https://nodragem.github.io/Blog/project/proto-bubble-squad/</link>
      <pubDate>Mon, 12 Mar 2018 14:50:11 +0000</pubDate>
      
      <guid>https://nodragem.github.io/Blog/project/proto-bubble-squad/</guid>
      <description>&lt;iframe frameborder=&#34;0&#34; src=&#34;https://proto-bubble-squad.herokuapp.com&#34; allowfullscreen=&#34;&#34; width=&#34;1000&#34; height=&#34;700&#34;&gt;
 &lt;p&gt;Your browser does not support iframes. Please try the game here: https://proto-bubble-squad.herokuapp.com &lt;/p&gt;
&lt;/iframe&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-warning&#34;&gt;
  
Camera movement could not be implemented in this version, you may need to drag the camera around to find your bubble troop.

&lt;/div&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  
This is a multiplayer game, you can open two tabs to play it against yourselve.

&lt;/div&gt;
&lt;/p&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;p&gt;This game is compatible with mobile devices and desktop computers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Click on the ground and drag to move the camera&lt;/li&gt;
&lt;li&gt;Click on a bubble and drag to catapult it&lt;/li&gt;
&lt;li&gt;Click on the top-left icon to enable fullscreen&lt;/li&gt;
&lt;li&gt;Collide with a friend to heal it&lt;/li&gt;
&lt;li&gt;Collide with an ennemy to hurt it&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If for some reason the controls are still not working try refresh the page or go back to the previous page and click on the link again.&lt;/p&gt;
&lt;h2 id=&#34;credits&#34;&gt;Credits&lt;/h2&gt;
&lt;p&gt;This prototype was developped to test the ideas of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Adrien Lebouc&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Game made with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Phaser&lt;/strong&gt; (Game Engine): &lt;a href=&#34;https://phaser.io/&#34;&gt;https://phaser.io/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Inkscape&lt;/strong&gt; (2D Graphics): &lt;a href=&#34;https://inkscape.org/en/&#34;&gt;https://inkscape.org/en/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tiled map&lt;/strong&gt; (Level Editor): &lt;a href=&#34;http://www.mapeditor.org/&#34;&gt;http://www.mapeditor.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LabChirp&lt;/strong&gt; (Sound FX): &lt;a href=&#34;http://labbed.net/software/labchirp/&#34;&gt;http://labbed.net/software/labchirp/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TexturePacker (Free Version)&lt;/strong&gt; (Texture Atlas): &lt;a href=&#34;https://www.codeandweb.com/texturepacker&#34;&gt;https://www.codeandweb.com/texturepacker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Cannon Shooter</title>
      <link>https://nodragem.github.io/Blog/project/cannon-shooter/</link>
      <pubDate>Mon, 12 Mar 2018 13:48:11 +0000</pubDate>
      
      <guid>https://nodragem.github.io/Blog/project/cannon-shooter/</guid>
      <description>&lt;iframe frameborder=&#34;0&#34; src=&#34;https://proto-cannon-shooter.herokuapp.com/&#34; allowfullscreen=&#34;&#34; width=&#34;650&#34; height=&#34;480&#34;&gt;
 &lt;p&gt;Your browser does not support iframes. Please try the game here: https://proto-cannon-shooter.herokuapp.com/ &lt;/p&gt;
&lt;/iframe&gt;
&lt;p&gt;It may take few seconds for the server to wake up, please wait&amp;hellip;&lt;/p&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;p&gt;Click on the game to enable the keyboard inputs.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LEFT and RIGHT to move&lt;/li&gt;
&lt;li&gt;SPACE to shoot&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If for some reason the controls are still not working try refresh the page or go back to the previous page and click on the link again.&lt;/p&gt;
&lt;h2 id=&#34;credits&#34;&gt;Credits&lt;/h2&gt;
&lt;p&gt;Software used:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Phaser&lt;/strong&gt; (Game Engine): &lt;a href=&#34;https://phaser.io/&#34;&gt;https://phaser.io/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DragonBones&lt;/strong&gt; (Animation): &lt;a href=&#34;http://dragonbones.com/en/index.html&#34;&gt;http://dragonbones.com/en/index.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Inkscape&lt;/strong&gt; (2D Graphics): &lt;a href=&#34;https://inkscape.org/en/&#34;&gt;https://inkscape.org/en/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LabChirp&lt;/strong&gt; (Sound FX): &lt;a href=&#34;http://labbed.net/software/labchirp/&#34;&gt;http://labbed.net/software/labchirp/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LMMS&lt;/strong&gt; (Music): &lt;a href=&#34;https://lmms.io/&#34;&gt;https://lmms.io/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TexturePacker (Free Version)&lt;/strong&gt; (Texture Atlas): &lt;a href=&#34;https://www.codeandweb.com/texturepacker&#34;&gt;https://www.codeandweb.com/texturepacker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Simulating Lag and Drop when Debugging Multiplayer Games</title>
      <link>https://nodragem.github.io/Blog/post/gamedev/18022018_clumsy/</link>
      <pubDate>Sun, 18 Feb 2018 17:14:08 +0100</pubDate>
      
      <guid>https://nodragem.github.io/Blog/post/gamedev/18022018_clumsy/</guid>
      <description>&lt;h2 id=&#34;debugging-multiplayer-games-locally&#34;&gt;Debugging multiplayer games locally&lt;/h2&gt;
&lt;p&gt;These days, I&amp;rsquo;m playing around with making online multiplayer prototype games.&lt;/p&gt;
&lt;p&gt;Most of the time, when we debug our video games for online multiplayer, we run a local server on &lt;code&gt;localhost&lt;/code&gt;. This server acts as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a file server - sending the game files to the client,&lt;/li&gt;
&lt;li&gt;a game server - transferring information between clients, authorizing transactions, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can debug your code logic on server side and client side very easily nowadays. For instance, I use VS Code, with NodeJS to debug the server side and the Chrome debugger plug-in to debug the client side.&lt;/p&gt;
&lt;p&gt;However, once your game works perfectly with your local server, it only means that it works perfectly with &lt;em&gt;perfect network condition!&lt;/em&gt; You are still miles away from having a game working in real world network conditions.&lt;/p&gt;
&lt;p&gt;When released, your multiplayer code will have to deal with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;variable delays of communication between clients and server,&lt;/li&gt;
&lt;li&gt;variable number of dropped messages/packages.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Although software like Unity offers to simulate this kind of disruptions, we are not all and/or always using Unity :D ! I am using Phaser right now. After some research I found a little piece of software allowing to simulate real-word network condition locally, so I thought I will share.&lt;/p&gt;
&lt;h2 id=&#34;clumsy-an-utility-to-simulate-broken-network&#34;&gt;Clumsy an utility to simulate broken network&lt;/h2&gt;
&lt;p&gt;This piece of software is named &lt;code&gt;clumsy&lt;/code&gt; and can be found [here] (&lt;a href=&#34;https://jagt.github.io/clumsy/)&#34;&gt;https://jagt.github.io/clumsy/)&lt;/a&gt;. According to their website:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;clumsy makes your network condition on Windows significantly worse, but in a managed and interactive manner.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure&gt;
    &lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/18022018_clumsy/clumsy.png&#34;/&gt; 
&lt;/figure&gt;

&lt;p&gt;What&amp;rsquo;s nice about it is that it does not require any installation and works out-of-the box. When unzipped, &lt;code&gt;clumsy&lt;/code&gt; sits next to a file &lt;code&gt;config.txt&lt;/code&gt; where you can specify exactly which part of the network you want to disrupt.&lt;/p&gt;
&lt;p&gt;For instance, if I host my server on &lt;code&gt;localhost:5000&lt;/code&gt;, I can make a configuration that disrupt the access to &lt;code&gt;localhost:5000&lt;/code&gt;. To do so, I added the following in &lt;code&gt;config.txt&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;HTML5 games: outbound and tcp.DstPort == 5000
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After that, when you open Clumsy, you will be able to select the configuration &lt;code&gt;HTML5 games&lt;/code&gt; from the droplist menu.&lt;/p&gt;
&lt;figure&gt;
    &lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/18022018_clumsy/clumsy_html5games.png&#34;/&gt; 
&lt;/figure&gt;

&lt;p&gt;Note that the configuration &lt;code&gt;localhost ipv4 all&lt;/code&gt; does roughlythe same as my config except that it disrupts &lt;em&gt;any&lt;/em&gt; local hosts.&lt;/p&gt;
&lt;h2 id=&#34;experimenting-with-delayed-and-dropped-packages&#34;&gt;Experimenting with Delayed and Dropped Packages&lt;/h2&gt;
&lt;p&gt;To give you a better idea of how network dirupstion translates into your game, I tested &lt;code&gt;clumsy&lt;/code&gt; on a prototype I made recently. I used a client authoritative network with two clients and one server to keep things simple.&lt;/p&gt;
&lt;p&gt;What I mean by Client Authoritative is that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Client 1 (on the top) applies the input of the player without delay,&lt;/li&gt;
&lt;li&gt;Client 1 sends the position of the charactor to the server,&lt;/li&gt;
&lt;li&gt;The server transmits the position to Client 2&lt;/li&gt;
&lt;li&gt;Client 2 (on the bottom) applies the position&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Basically, the server does not nothing but transmitting information between Client 1 and Client 2. Obviously, in practice, you would not do that to avoid cheating, but that &amp;rsquo;s ok for our example.&lt;/p&gt;
&lt;figure&gt;
    &lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/18022018_clumsy/all_0lag_0drop.gif&#34;/&gt; 
&lt;/figure&gt;

&lt;p&gt;Without delay and with 0% of dropped packages, the game works like a charm. However, we have no feel of what the players will be experiencing.&lt;/p&gt;
&lt;figure&gt;
    &lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/18022018_clumsy/all_1000lag_0drop.gif&#34;/&gt; 
&lt;/figure&gt;

&lt;p&gt;When we add some delays (1000 ms), the game still works, and we can test how the game feels with the server-to-client delay.  However, &lt;code&gt;clumsy&lt;/code&gt;&#39;s delays seem to be &lt;em&gt;fixed&lt;/em&gt;, as opposed to be &lt;em&gt;random&lt;/em&gt;, which is most probably the case in real network.&lt;/p&gt;
&lt;p&gt;With &lt;em&gt;random&lt;/em&gt; delays, you would experience bugs if your code relies on messages arriving to the server in the order they have been sent. For instance, something like that would lead to bugs:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-javascript&#34; data-lang=&#34;javascript&#34;&gt;[&lt;span style=&#34;color:#06b6ef&#34;&gt;Client&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;Side&lt;/span&gt;]

&lt;span style=&#34;color:#815ba4&#34;&gt;this&lt;/span&gt;.&lt;span style=&#34;color:#06b6ef&#34;&gt;_socket&lt;/span&gt;.&lt;span style=&#34;color:#06b6ef&#34;&gt;emit&lt;/span&gt;(&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;spawning_points_request&amp;#39;&lt;/span&gt;);
&lt;span style=&#34;color:#815ba4&#34;&gt;this&lt;/span&gt;.&lt;span style=&#34;color:#06b6ef&#34;&gt;_socket&lt;/span&gt;.&lt;span style=&#34;color:#06b6ef&#34;&gt;emit&lt;/span&gt;(&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;new_player_request&amp;#39;&lt;/span&gt;);

&lt;span style=&#34;color:#06b6ef&#34;&gt;self&lt;/span&gt; &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#815ba4&#34;&gt;this&lt;/span&gt;;
&lt;span style=&#34;color:#815ba4&#34;&gt;this&lt;/span&gt;.&lt;span style=&#34;color:#06b6ef&#34;&gt;_socket&lt;/span&gt;.&lt;span style=&#34;color:#06b6ef&#34;&gt;on&lt;/span&gt;(&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;spawning_points&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#815ba4&#34;&gt;function&lt;/span&gt;(&lt;span style=&#34;color:#06b6ef&#34;&gt;data&lt;/span&gt;){
            &lt;span style=&#34;color:#06b6ef&#34;&gt;self&lt;/span&gt;.&lt;span style=&#34;color:#06b6ef&#34;&gt;spawning_points&lt;/span&gt; &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;data&lt;/span&gt;.&lt;span style=&#34;color:#06b6ef&#34;&gt;spawning_points&lt;/span&gt;;
        });

&lt;span style=&#34;color:#815ba4&#34;&gt;this&lt;/span&gt;.&lt;span style=&#34;color:#06b6ef&#34;&gt;_socket&lt;/span&gt;.&lt;span style=&#34;color:#06b6ef&#34;&gt;on&lt;/span&gt;(&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;new_player&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#815ba4&#34;&gt;function&lt;/span&gt;(&lt;span style=&#34;color:#06b6ef&#34;&gt;data&lt;/span&gt;){
            &lt;span style=&#34;color:#06b6ef&#34;&gt;self&lt;/span&gt;.&lt;span style=&#34;color:#06b6ef&#34;&gt;addPlayer&lt;/span&gt;(&lt;span style=&#34;color:#06b6ef&#34;&gt;data&lt;/span&gt;.&lt;span style=&#34;color:#06b6ef&#34;&gt;player&lt;/span&gt;, &lt;span style=&#34;color:#06b6ef&#34;&gt;self&lt;/span&gt;.&lt;span style=&#34;color:#06b6ef&#34;&gt;spawning_positions&lt;/span&gt;[&lt;span style=&#34;color:#f99b15&#34;&gt;0&lt;/span&gt;]);
        });

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In this code, the spawning positions must be received from the server before that the new player is received. While we requested the spawning positions first, a real network would not guarantee that you will receive the spawning points first. If I understand well, in &lt;code&gt;clumsy&lt;/code&gt;, you can emulate that behaviour with the &lt;code&gt;Out of order&lt;/code&gt; option.&lt;/p&gt;
&lt;figure&gt;
    &lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/18022018_clumsy/all_50lag_20drop.gif&#34;/&gt; 
&lt;/figure&gt;

&lt;p&gt;Finally, when we add dropped packages, things can become a big mess. In our example, Client 2 (bottom) always succeeds to catch up with Client 1 (top)  because Client 1 sends the &lt;em&gt;position&lt;/em&gt; of the character and not the change in position.&lt;/p&gt;
&lt;p&gt;However, if your code relies on sending changes in state (i.e. delta method) or on sending an important message, you may experience bugs as these messages are dropped. For instance, in this simple example, I only send once the message to request a new player to the server. If it does not reach the server, I need to reload the page, until it does!&lt;/p&gt;
&lt;p&gt;Hope you will have fun debugging with &lt;code&gt;clumsy&lt;/code&gt;. If you know other useful tools for debugging multiplayer online game, let us know in the comments below!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>It&#39;s a Match!</title>
      <link>https://nodragem.github.io/Blog/project/its-a-match/</link>
      <pubDate>Tue, 12 Dec 2017 13:48:11 +0000</pubDate>
      
      <guid>https://nodragem.github.io/Blog/project/its-a-match/</guid>
      <description>&lt;iframe frameborder=&#34;0&#34; src=&#34;https://itch.io/embed-upload/822309?color=333333&#34; allowfullscreen=&#34;&#34; width=&#34;960&#34; height=&#34;540&#34;&gt;
 &lt;p&gt;Your browser does not support iframes. Please try the game here: https://nodragem.itch.io/john-space &lt;/p&gt;
&lt;/iframe&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;p&gt;Click on the game to enable the keyboard inputs.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;KEYBOARD ARROWS to move&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If for some reason the controls are still not working try refresh the page or go back to the previous page and click on the link again.&lt;/p&gt;
&lt;h2 id=&#34;credits&#34;&gt;Credits&lt;/h2&gt;
&lt;p&gt;Extract of the game made for the GWJam 2017 (Theme: 2 is better than 1) in collaboration with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Karl Jones&lt;/li&gt;
&lt;li&gt;Steven Sparkes&lt;/li&gt;
&lt;li&gt;Jonathan Raymond Westlake&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Software used:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Unity&lt;/strong&gt; (Game Engine): &lt;a href=&#34;https://unity3d.com/&#34;&gt;https://unity3d.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Blender&lt;/strong&gt; (3D Graphics): &lt;a href=&#34;https://www.blender.org/&#34;&gt;https://www.blender.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Catch The Crown!</title>
      <link>https://nodragem.github.io/Blog/project/catchthecrown/</link>
      <pubDate>Sat, 15 Apr 2017 14:51:57 +0100</pubDate>
      
      <guid>https://nodragem.github.io/Blog/project/catchthecrown/</guid>
      <description>&lt;h2 id=&#34;download&#34;&gt;Download&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Windows, portable version (&lt;a href=&#34;https://github.com/Nodragem/Catch-the-Crown/releases/download/v0.9-alpha/catchthecrown_win32.zip&#34;&gt;zip-file&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Linux, portable version (&lt;a href=&#34;https://github.com/Nodragem/Catch-the-Crown/releases/download/v0.9-alpha/catchthecrown_linux32.zip&#34;&gt;zip-file&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Mac OS, portable version (&lt;a href=&#34;https://github.com/Nodragem/Catch-the-Crown/releases/download/v0.9-alpha/catchthecrown_mac.zip&#34;&gt;zip-file&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  
I could not actually test the Mac / Linux versions. Please let me know if the game does not run on your platform.

&lt;/div&gt;

&lt;h2 id=&#34;release-notes&#34;&gt;Release Notes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://nodragem.github.io/Blog/Blog/post/gamedev/catchthecrown_release/&#34;&gt;Relase Notes of The Prabbits: Catch the Crown&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;description&#34;&gt;description&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;The Prabbits: Catch The Crown&lt;/strong&gt; is a local multiplayer arena platform game.&lt;/p&gt;
&lt;p&gt;Four teenager Prabbits - half parrot / half rabbit creatures - are undertaking their &amp;ldquo;Coming-of-Age&amp;rdquo; ritual. They are spawned in an arena with a crown and a timer. Once the crown is picked up by a Prabbit, coins, diamonds and rubies appear across the level. Only the Prabbit with the crown can collect them.&lt;/p&gt;
&lt;p&gt;A competition starts between Prabbits to catch the crown and collect gold. When the timer ends, the richer Prabbit wins.&lt;/p&gt;
&lt;h2 id=&#34;credits&#34;&gt;Credits&lt;/h2&gt;
&lt;p&gt;I need to thank my friends for their ideas and feedback, especially:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Arthur Portron&lt;/li&gt;
&lt;li&gt;Lukas Wolf&lt;/li&gt;
&lt;li&gt;Atanaska Nikolova&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Software used:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;libGDX&lt;/strong&gt; (Game Engine): &lt;a href=&#34;https://libgdx.badlogicgames.com/&#34;&gt;https://libgdx.badlogicgames.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gimp&lt;/strong&gt; (2D Graphics): &lt;a href=&#34;https://www.gimp.org/&#34;&gt;https://www.gimp.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Krita&lt;/strong&gt; (2D Graphics/Painting): &lt;a href=&#34;https://krita.org/en/&#34;&gt;https://krita.org/en/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Aseprite&lt;/strong&gt; (2D Graphics/Animation): &lt;a href=&#34;https://www.aseprite.org/&#34;&gt;https://www.aseprite.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;sfxr/bfxr&lt;/strong&gt; (Sound FX): &lt;a href=&#34;https://www.bfxr.net/&#34;&gt;https://www.bfxr.net/&lt;/a&gt; &lt;a href=&#34;http://www.drpetter.se/project_sfxr.html&#34;&gt;http://www.drpetter.se/project_sfxr.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Audacity&lt;/strong&gt; (Voice Recording and Editing): &lt;a href=&#34;https://www.audacityteam.org/&#34;&gt;https://www.audacityteam.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LMMS&lt;/strong&gt; (Music): &lt;a href=&#34;https://lmms.io/&#34;&gt;https://lmms.io/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;customization&#34;&gt;Customization&lt;/h2&gt;
&lt;h3 id=&#34;asset-folder&#34;&gt;Asset folder&lt;/h3&gt;
&lt;p&gt;The assets are accessible and can be modified, that means you can add new levels and change the animations or sounds if you wanted to.&lt;/p&gt;
&lt;h3 id=&#34;preference-files&#34;&gt;Preference Files&lt;/h3&gt;
&lt;p&gt;The preference files are in the folder &lt;code&gt;preference&lt;/code&gt; and they can be modified to make the game windowed or fullscreen, change the name of the characters, or even use the keyboard as input.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Use the &lt;strong&gt;Keyboard and Mouse input&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;Open the file &lt;code&gt;preferences.json&lt;/code&gt; in &lt;code&gt;./preference&lt;/code&gt; and replace, for instance:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;quot;input&amp;quot;: &amp;quot;controller&amp;quot;,
&amp;quot;id_input&amp;quot;: 2
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;quot;input&amp;quot;: &amp;quot;keyboard&amp;quot;,
&amp;quot;id_input&amp;quot;: 1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Note that the &lt;code&gt;id_input&lt;/code&gt; of the keyboard must be set to 1.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Change the &lt;strong&gt;names of the Prabbits&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;Open the file &lt;code&gt;preferences.json&lt;/code&gt; in &lt;code&gt;./preference&lt;/code&gt; and replace, for instance:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;quot;name&amp;quot;: &amp;quot;Purple&amp;quot;,
&amp;quot;color&amp;quot;: &amp;quot;purple&amp;quot;,
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;quot;name&amp;quot;: &amp;quot;MyNewName&amp;quot;,
&amp;quot;color&amp;quot;: &amp;quot;purple&amp;quot;,
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Change &lt;strong&gt;FullScreen Mode and Resolution&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;Open the file &lt;code&gt;preferences.json&lt;/code&gt; in &lt;code&gt;./preference&lt;/code&gt; and replace, for instance:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;quot;full_screen&amp;quot;: true,
&amp;quot;resolution&amp;quot;: [1920, 1080],
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;quot;full_screen&amp;quot;: false,
&amp;quot;resolution&amp;quot;: [800, 600],
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Change the Controls:&lt;/p&gt;
&lt;p&gt;The controls are mapped to actions in the files &lt;code&gt;profileController.xml&lt;/code&gt; and &lt;code&gt;profileKeyBoard.xml&lt;/code&gt;. Note that the Mouse controls are hard coded and cannot be modified. The numbers mapped to the buttons of your controller depend on your controller.
Known mapping can be found &lt;a href=&#34;https://github.com/libgdx/libgdx/tree/master/extensions/gdx-controllers/gdx-controllers/src/com/badlogic/gdx/controllers/mappings&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- ## Screenshot: 
 &lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/catchthecrown_release/catch_crown.gif&#34; width=&#34;100%&#34;/&gt; --&gt;
</description>
    </item>
    
    <item>
      <title>Data extraction with WebPlotDigitizer</title>
      <link>https://nodragem.github.io/Blog/post/research/analyse_extracted_data/</link>
      <pubDate>Fri, 14 Apr 2017 12:43:08 +0100</pubDate>
      
      <guid>https://nodragem.github.io/Blog/post/research/analyse_extracted_data/</guid>
      <description>&lt;h2 id=&#34;when-weve-only-got-a-picture-to-create-a-model&#34;&gt;When we&amp;rsquo;ve only got a picture to create a model&lt;/h2&gt;
&lt;p&gt;Recently, I wanted to generate realistic
durations of fast eye movements (saccades) in a stochastic manner.&lt;/p&gt;
&lt;p&gt;Few articles plot what we call &amp;ldquo;the main sequence&amp;rdquo; which describes the saccade
duration against saccade magnitude (i.e. amplitude), such as in
Troncoso et al. (2008):&lt;/p&gt;
&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/research/analyseExtractedData_files/figure-markdown/main_sequence.png&#34; width=&#34;500px&#34; height=&#34;500px&#34;/&gt;
&lt;p style=&#34;font-size:0.6rem;&#34;&gt;&lt;i&gt;Data from Troncoso, X. G., Macknik, S. L., &amp; Martinez-Conde, S. (2008).
Microsaccades counteract perceptual filling-in. Journal of Vision,
8(14):15, 1-9&lt;/i&gt; [ARVO is the copyright holder]&lt;/p&gt;
&lt;p&gt;There are 3 main problems though:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;we don&amp;rsquo;t have access to the original data used to generate this plot,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;there is many data points and the picture quality is quite poor,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;the plot is in logscale, so it might be hard to get an eyeball
estimation of the regression line.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Without at least an estimation of the data points, we cannot build a realistic model.&lt;/p&gt;
&lt;h2 id=&#34;using-a-data-extractor&#34;&gt;Using a Data Extractor&lt;/h2&gt;
&lt;p&gt;WebPlotDigitizer (&lt;a href=&#34;http://arohatgi.info/WebPlotDigitizer/&#34;&gt;here&lt;/a&gt;) is a
data extractor that, among other things, allows us to calibrate the axis
of the figure to extract in logspace. I tried it on Troncoso et al.&amp;rsquo;s
figure, without real hope of obtaining something decent because of the
jped compression (my real hope was to manually draw a regression line in
that jpeg fog).&lt;/p&gt;
&lt;p&gt;Here are the steps, recorded with ScreenToGif.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/research/analyseExtractedData_files/figure-markdown/webplotdigitizer.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;The result is quite impressive when considering the picture quality.
Here is what I obtained with the automatic extraction! Let see how this
looks like once exported in CSV and plotted in R.&lt;/p&gt;
&lt;p&gt;We show the first lines of the file:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;df1 &lt;span style=&#34;color:#5bc4bf&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;read.csv&lt;/span&gt;(&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#34;extraction1.csv&amp;#34;&lt;/span&gt;, header &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#815ba4&#34;&gt;FALSE&lt;/span&gt;) 
&lt;span style=&#34;color:#06b6ef&#34;&gt;setnames&lt;/span&gt;(df1, &lt;span style=&#34;color:#06b6ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;amplitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;duration&amp;#39;&lt;/span&gt;))
&lt;span style=&#34;color:#06b6ef&#34;&gt;head&lt;/span&gt;(df1, &lt;span style=&#34;color:#f99b15&#34;&gt;5&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;##    amplitude duration
## 1 0.07355096 6.124430
## 2 0.08775247 5.467178
## 3 0.08825364 6.549086
## 4 0.08875767 5.453267
## 5 0.08901076 6.557844
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We print the number of data points that have been extracted:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;dim&lt;/span&gt;(df1)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;## [1] 5725    2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We plot the data:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;plot&lt;/span&gt;(df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;amplitude, df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;duration, xlim&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#f99b15&#34;&gt;0.01&lt;/span&gt;, &lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;), ylim&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#f99b15&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#f99b15&#34;&gt;30&lt;/span&gt;),
     main&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;df1&amp;#39;&lt;/span&gt;, pch&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;.&amp;#39;&lt;/span&gt; , log&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#34;xy&amp;#34;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/research/analyseExtractedData_files/figure-markdown/unnamed-chunk-1-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;That looks quite impressive for a data extraction made on a blurry jpeg!&lt;/p&gt;
&lt;p&gt;WebPlotDigitizer is not extracting &amp;ldquo;real&amp;rdquo; data points (which are almost
invisible on the orginal figure), but still the density of the data points
seems to correctly estimates the density of the original data. This
should be enough to compute a good estimate of the regression line of
the mean duration and of its standard deviation. So now, let us try to
compute these regression lines and make a saccade duration generator.&lt;/p&gt;
&lt;h2 id=&#34;compute-the-regression-model&#34;&gt;Compute the Regression model&lt;/h2&gt;
&lt;p&gt;We should start with finding the regression line in logspace.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;log_duration &lt;span style=&#34;color:#5bc4bf&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;log&lt;/span&gt;(df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;duration)
df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;log_amplitude &lt;span style=&#34;color:#5bc4bf&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;log&lt;/span&gt;(df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;amplitude)
log.model &lt;span style=&#34;color:#5bc4bf&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;lm&lt;/span&gt;( log_duration &lt;span style=&#34;color:#5bc4bf&#34;&gt;~&lt;/span&gt; log_amplitude, data&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;df1)
new &lt;span style=&#34;color:#5bc4bf&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;data.frame&lt;/span&gt;(log_amplitude &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;seq&lt;/span&gt;(&lt;span style=&#34;color:#06b6ef&#34;&gt;min&lt;/span&gt;(df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;log_amplitude), &lt;span style=&#34;color:#06b6ef&#34;&gt;max&lt;/span&gt;(df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;log_amplitude), &lt;span style=&#34;color:#f99b15&#34;&gt;0.01&lt;/span&gt;))
y_values &lt;span style=&#34;color:#5bc4bf&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;predict&lt;/span&gt;(log.model, new, interval&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#34;predict&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#06b6ef&#34;&gt;plot&lt;/span&gt;(df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;log_amplitude, df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;log_duration,
     main&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;df1&amp;#39;&lt;/span&gt;, pch&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;.&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#06b6ef&#34;&gt;lines&lt;/span&gt;(new&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;log_amplitude, y_values[,&lt;span style=&#34;color:#f99b15&#34;&gt;1&lt;/span&gt;], lwd&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;, col&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;red&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#06b6ef&#34;&gt;lines&lt;/span&gt;(new&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;log_amplitude, y_values[,&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;], lwd&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;, col&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;red&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#06b6ef&#34;&gt;lines&lt;/span&gt;(new&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;log_amplitude, y_values[,&lt;span style=&#34;color:#f99b15&#34;&gt;3&lt;/span&gt;], lwd&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;, col&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;red&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/research/analyseExtractedData_files/figure-markdown/unnamed-chunk-2-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;In the linear space, we get this pretty curve and increasing standard
deviation.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;plot&lt;/span&gt;(df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;amplitude, df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;duration,
     main&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;df1&amp;#39;&lt;/span&gt;, pch&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;.&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#06b6ef&#34;&gt;lines&lt;/span&gt;(&lt;span style=&#34;color:#06b6ef&#34;&gt;exp&lt;/span&gt;(new&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;log_amplitude), &lt;span style=&#34;color:#06b6ef&#34;&gt;exp&lt;/span&gt;(y_values[,&lt;span style=&#34;color:#f99b15&#34;&gt;1&lt;/span&gt;]), lwd&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;, col&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;red&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#06b6ef&#34;&gt;lines&lt;/span&gt;(&lt;span style=&#34;color:#06b6ef&#34;&gt;exp&lt;/span&gt;(new&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;log_amplitude), &lt;span style=&#34;color:#06b6ef&#34;&gt;exp&lt;/span&gt;(y_values[,&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;]), lwd&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;, col&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;red&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#06b6ef&#34;&gt;lines&lt;/span&gt;(&lt;span style=&#34;color:#06b6ef&#34;&gt;exp&lt;/span&gt;(new&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;log_amplitude), &lt;span style=&#34;color:#06b6ef&#34;&gt;exp&lt;/span&gt;(y_values[,&lt;span style=&#34;color:#f99b15&#34;&gt;3&lt;/span&gt;]), lwd&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;, col&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;red&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/research/analyseExtractedData_files/figure-markdown/unnamed-chunk-3-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;extract-the-equations&#34;&gt;Extract the equations&lt;/h2&gt;
&lt;p&gt;To be able to generate data from the regression, we must extract the
equations that describes :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the mean duration of saccades according to their amplitude,&lt;/li&gt;
&lt;li&gt;the standard deviation according to their amplitude.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That is a bit more complicated as usual because of the logspace, but it
is feasible.&lt;/p&gt;
&lt;h3 id=&#34;estimate-the-equation-of-the-mean&#34;&gt;Estimate the equation of the mean&lt;/h3&gt;
&lt;p&gt;It is easy to get the coefficients from the regression line.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;b &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; log.model&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;coefficients[[1]]
a &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; log.model&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;coefficients[[2]]

x &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; new&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;log_amplitude
reg_eq &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; a
y &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; a&lt;span style=&#34;color:#5bc4bf&#34;&gt;*&lt;/span&gt;x &lt;span style=&#34;color:#5bc4bf&#34;&gt;+&lt;/span&gt; b

&lt;span style=&#34;color:#06b6ef&#34;&gt;plot&lt;/span&gt;(df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;log_amplitude, df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;log_duration,
     main&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;df1&amp;#39;&lt;/span&gt;, pch&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;.&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#06b6ef&#34;&gt;lines&lt;/span&gt;(x, y, lwd&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;, col&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;red&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/research/analyseExtractedData_files/figure-markdown/unnamed-chunk-4-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Let pass the regression line in linear space. We got:&lt;/p&gt;
&lt;p&gt;$$
y_{ \text{log} } = a x_{ \text{log} } + b
$$&lt;/p&gt;
&lt;p&gt;and:&lt;/p&gt;
&lt;p&gt;$$
y_{lin} = exp(y_{log}) \\\&lt;br&gt;
x_{lin} = exp(x_{log})
$$&lt;/p&gt;
&lt;p&gt;So that, when combined, that gives:&lt;/p&gt;
&lt;p&gt;$$
y_{lin} = exp(ax_{log} + b) = exp(ax_{log}) * exp(b) \\\&lt;br&gt;
= exp(x_{log})^a . exp(b) \\\&lt;br&gt;
= x_{lin}^a . exp(b)
$$&lt;/p&gt;
&lt;p&gt;With we should be able to plot the regression line in linear space:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;cart_x &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;seq&lt;/span&gt;(&lt;span style=&#34;color:#06b6ef&#34;&gt;min&lt;/span&gt;(df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;amplitude), &lt;span style=&#34;color:#06b6ef&#34;&gt;max&lt;/span&gt;(df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;amplitude), &lt;span style=&#34;color:#f99b15&#34;&gt;0.01&lt;/span&gt;)
cart_y &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; (cart_x^a) &lt;span style=&#34;color:#5bc4bf&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;exp&lt;/span&gt;(b)
&lt;span style=&#34;color:#06b6ef&#34;&gt;plot&lt;/span&gt;(df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;amplitude, df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;duration,
     main&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;df1&amp;#39;&lt;/span&gt;, pch&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;.&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#06b6ef&#34;&gt;lines&lt;/span&gt;(cart_x, cart_y, lwd&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;, col&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;red&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/research/analyseExtractedData_files/figure-markdown/unnamed-chunk-5-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Yeah! we got it. Now let us extract the equation for the standard
deviation.&lt;/p&gt;
&lt;h3 id=&#34;estimate-the-standard-deviations&#34;&gt;Estimate the standard deviations&lt;/h3&gt;
&lt;p&gt;In logarithmic space, we get a standard deviation (SD) that is rather flat, althought
there may be a small irregularity on the right hand side.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;par&lt;/span&gt;(mfrow&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#f99b15&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;))

log_sd &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;abs&lt;/span&gt;(log.model&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;residuals)
&lt;span style=&#34;color:#06b6ef&#34;&gt;plot&lt;/span&gt;(df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;amplitude, log_sd, ylim&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#f99b15&#34;&gt;-1&lt;/span&gt;, &lt;span style=&#34;color:#f99b15&#34;&gt;1&lt;/span&gt;), xlim&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#f99b15&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f99b15&#34;&gt;1&lt;/span&gt;))

sd_change &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;rollapply&lt;/span&gt;(log_sd, width &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f99b15&#34;&gt;200&lt;/span&gt;, FUN &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; median, fill &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#815ba4&#34;&gt;NA&lt;/span&gt;)
&lt;span style=&#34;color:#06b6ef&#34;&gt;plot&lt;/span&gt;(df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;amplitude, sd_change, ylim&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#f99b15&#34;&gt;-1&lt;/span&gt;, &lt;span style=&#34;color:#f99b15&#34;&gt;1&lt;/span&gt; ), xlim&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#f99b15&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f99b15&#34;&gt;1&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/research/analyseExtractedData_files/figure-markdown/unnamed-chunk-6-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Unfortunately, to find the change in variance in the cartesian space is
not as simple as taking the exponential of the logspace&amp;rsquo;s variance.&lt;/p&gt;
&lt;p&gt;First, let us compute the standard deviation and its trends in the
cartesian space.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;&lt;span style=&#34;color:#776e71&#34;&gt;# remember that:&lt;/span&gt;
&lt;span style=&#34;color:#776e71&#34;&gt;# cart_x = seq(min(df1$amplitude), max(df1$amplitude), 0.01)&lt;/span&gt;
&lt;span style=&#34;color:#776e71&#34;&gt;# cart_y = (cart_x^a) * exp(b)&lt;/span&gt;

cart_sd &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;abs&lt;/span&gt;(df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;duration &lt;span style=&#34;color:#5bc4bf&#34;&gt;-&lt;/span&gt; (df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;amplitude^a)&lt;span style=&#34;color:#5bc4bf&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;exp&lt;/span&gt;(b))

&lt;span style=&#34;color:#06b6ef&#34;&gt;par&lt;/span&gt;(mfrow&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#f99b15&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;))
&lt;span style=&#34;color:#06b6ef&#34;&gt;plot&lt;/span&gt;(df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;amplitude, cart_sd, xlim&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#f99b15&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f99b15&#34;&gt;1&lt;/span&gt;))

&lt;span style=&#34;color:#776e71&#34;&gt;# moving windows that take the median of the duration&amp;#39;s sd over saccade amplitude&lt;/span&gt;
sd_change &lt;span style=&#34;color:#5bc4bf&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;rollapply&lt;/span&gt;(cart_sd, width &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f99b15&#34;&gt;200&lt;/span&gt;, FUN &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; median, fill &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#815ba4&#34;&gt;NA&lt;/span&gt;)
&lt;span style=&#34;color:#06b6ef&#34;&gt;plot&lt;/span&gt;(df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;amplitude, sd_change, xlim&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#f99b15&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f99b15&#34;&gt;1&lt;/span&gt;))
df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;sd_duration &lt;span style=&#34;color:#5bc4bf&#34;&gt;&amp;lt;-&lt;/span&gt; sd_change

&lt;span style=&#34;color:#776e71&#34;&gt;# regression of the duration sd over amplitude&lt;/span&gt;
var.model &lt;span style=&#34;color:#5bc4bf&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;lm&lt;/span&gt;(sd_duration &lt;span style=&#34;color:#5bc4bf&#34;&gt;~&lt;/span&gt; amplitude, data &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; df1)
curve_y &lt;span style=&#34;color:#5bc4bf&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;predict&lt;/span&gt;(var.model, &lt;span style=&#34;color:#06b6ef&#34;&gt;data.frame&lt;/span&gt;(amplitude&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;cart_x) )
&lt;span style=&#34;color:#06b6ef&#34;&gt;lines&lt;/span&gt;(cart_x, curve_y, lwd&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;, col&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/research/analyseExtractedData_files/figure-markdown/unnamed-chunk-7-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;sd_b &lt;span style=&#34;color:#5bc4bf&#34;&gt;&amp;lt;-&lt;/span&gt; var.model&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;coefficients[[1]]
sd_a &lt;span style=&#34;color:#5bc4bf&#34;&gt;&amp;lt;-&lt;/span&gt; var.model&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;coefficients[[2]]
var.model&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;coefficients
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;## (Intercept)   amplitude 
##   0.5487717   3.5581414
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From the previous plot, it seems that a linear increase of SD with
amplitude is a good approximation. However, we may not want the SD to
diverge too much. Let us try with a model of variance that have a
horizontal asymptote, for instance &lt;code&gt;1-exp(-amplitude)&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;exp_amplitude &lt;span style=&#34;color:#5bc4bf&#34;&gt;&amp;lt;-&lt;/span&gt; (&lt;span style=&#34;color:#f99b15&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#5bc4bf&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;exp&lt;/span&gt;(&lt;span style=&#34;color:#5bc4bf&#34;&gt;-&lt;/span&gt;df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;amplitude))
var.model &lt;span style=&#34;color:#5bc4bf&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;lm&lt;/span&gt;(sd_duration &lt;span style=&#34;color:#5bc4bf&#34;&gt;~&lt;/span&gt; exp_amplitude, data &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; df1)

var.model&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;coefficients
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;##   (Intercept) exp_amplitude 
##      0.285162      5.240037
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;sd_eb &lt;span style=&#34;color:#5bc4bf&#34;&gt;&amp;lt;-&lt;/span&gt; var.model&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;coefficients[[1]]
sd_ea &lt;span style=&#34;color:#5bc4bf&#34;&gt;&amp;lt;-&lt;/span&gt; var.model&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;coefficients[[2]]

&lt;span style=&#34;color:#776e71&#34;&gt;# we do the prediction ourselve:&lt;/span&gt;
&lt;span style=&#34;color:#776e71&#34;&gt;# we used SD.Duration = a * [1-exp(-amplitude)] + b, which gives:&lt;/span&gt;
curve_y &lt;span style=&#34;color:#5bc4bf&#34;&gt;&amp;lt;-&lt;/span&gt; (sd_ea &lt;span style=&#34;color:#5bc4bf&#34;&gt;+&lt;/span&gt; sd_eb) &lt;span style=&#34;color:#5bc4bf&#34;&gt;-&lt;/span&gt; sd_ea&lt;span style=&#34;color:#5bc4bf&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;exp&lt;/span&gt;(&lt;span style=&#34;color:#5bc4bf&#34;&gt;-&lt;/span&gt;cart_x)

&lt;span style=&#34;color:#06b6ef&#34;&gt;plot&lt;/span&gt;(df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;amplitude, sd_change, xlim&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#f99b15&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f99b15&#34;&gt;1&lt;/span&gt;))
&lt;span style=&#34;color:#06b6ef&#34;&gt;lines&lt;/span&gt;(cart_x, curve_y, lwd&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;, col&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/research/analyseExtractedData_files/figure-markdown/unnamed-chunk-8-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;The asymptotic equation seems to approximate the SD as well as the linear
equation.&lt;/p&gt;
&lt;p&gt;To judge which is best, let us plot both the equations we estimated
against the regression model we made earlier. Note that the regression
model was showing a 95% prediction interval (in red), which depends on
the SD that we formulated (in green and purple), but it is not expected
to be equal to it.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;plot&lt;/span&gt;(df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;amplitude, df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;duration,
     main&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;df1&amp;#39;&lt;/span&gt;, pch&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;.&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#776e71&#34;&gt;## regression fit:&lt;/span&gt;
&lt;span style=&#34;color:#06b6ef&#34;&gt;lines&lt;/span&gt;(&lt;span style=&#34;color:#06b6ef&#34;&gt;exp&lt;/span&gt;(new&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;log_amplitude), &lt;span style=&#34;color:#06b6ef&#34;&gt;exp&lt;/span&gt;(y_values[,&lt;span style=&#34;color:#f99b15&#34;&gt;1&lt;/span&gt;]), lwd&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;, col&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;red&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#06b6ef&#34;&gt;lines&lt;/span&gt;(&lt;span style=&#34;color:#06b6ef&#34;&gt;exp&lt;/span&gt;(new&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;log_amplitude), &lt;span style=&#34;color:#06b6ef&#34;&gt;exp&lt;/span&gt;(y_values[,&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;]), lwd&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;, col&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;red&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#06b6ef&#34;&gt;lines&lt;/span&gt;(&lt;span style=&#34;color:#06b6ef&#34;&gt;exp&lt;/span&gt;(new&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;log_amplitude), &lt;span style=&#34;color:#06b6ef&#34;&gt;exp&lt;/span&gt;(y_values[,&lt;span style=&#34;color:#f99b15&#34;&gt;3&lt;/span&gt;]), lwd&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;, col&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;red&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#776e71&#34;&gt;## our equations:&lt;/span&gt;
&lt;span style=&#34;color:#06b6ef&#34;&gt;lines&lt;/span&gt;(cart_x, cart_y, lwd&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;, col&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;green&amp;#39;&lt;/span&gt;, lty&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;)

&lt;span style=&#34;color:#776e71&#34;&gt;## linear sd&lt;/span&gt;
sd_y &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f99b15&#34;&gt;0.55&lt;/span&gt; &lt;span style=&#34;color:#5bc4bf&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#f99b15&#34;&gt;3.54&lt;/span&gt; &lt;span style=&#34;color:#5bc4bf&#34;&gt;*&lt;/span&gt; cart_x
&lt;span style=&#34;color:#06b6ef&#34;&gt;lines&lt;/span&gt;(cart_x, cart_y&lt;span style=&#34;color:#5bc4bf&#34;&gt;+&lt;/span&gt;sd_y, lwd&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;, col&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;green&amp;#39;&lt;/span&gt;, lty&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;)
&lt;span style=&#34;color:#06b6ef&#34;&gt;lines&lt;/span&gt;(cart_x, cart_y&lt;span style=&#34;color:#5bc4bf&#34;&gt;-&lt;/span&gt;sd_y, lwd&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;, col&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;green&amp;#39;&lt;/span&gt;, lty&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;)

&lt;span style=&#34;color:#776e71&#34;&gt;## assymtotic sd:&lt;/span&gt;
sd_y &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; (sd_ea &lt;span style=&#34;color:#5bc4bf&#34;&gt;+&lt;/span&gt; sd_eb) &lt;span style=&#34;color:#5bc4bf&#34;&gt;-&lt;/span&gt; sd_ea&lt;span style=&#34;color:#5bc4bf&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;exp&lt;/span&gt;(&lt;span style=&#34;color:#5bc4bf&#34;&gt;-&lt;/span&gt;cart_x)
&lt;span style=&#34;color:#06b6ef&#34;&gt;lines&lt;/span&gt;(cart_x, cart_y&lt;span style=&#34;color:#5bc4bf&#34;&gt;+&lt;/span&gt;sd_y, lwd&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;, col&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;purple&amp;#39;&lt;/span&gt;, lty&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;)
&lt;span style=&#34;color:#06b6ef&#34;&gt;lines&lt;/span&gt;(cart_x, cart_y&lt;span style=&#34;color:#5bc4bf&#34;&gt;-&lt;/span&gt;sd_y, lwd&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;, col&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;purple&amp;#39;&lt;/span&gt;, lty&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;2&lt;/span&gt;)
&lt;span style=&#34;color:#06b6ef&#34;&gt;legend&lt;/span&gt;(&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;bottomright&amp;#39;&lt;/span&gt;, legend&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;regresssion&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;linear SD equation&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;assymptotic SD equation&amp;#39;&lt;/span&gt;),lty&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;1&lt;/span&gt;, col&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;red&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;green&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;purple&amp;#39;&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/research/analyseExtractedData_files/figure-markdown/unnamed-chunk-9-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;It seems that the assymptotic equation of SD do a better job than the
linear equation. Furthermore, it is a wished property that the SD does
not diverge.&lt;/p&gt;
&lt;p&gt;Thus, to summarize, our full model of the duration of
saccade according to duration should follows:&lt;/p&gt;
&lt;!-- remember that:
cart_y = (cart_x^a) * exp(b)
sd_y = (sd_ea + sd_eb) - sd_ea*exp(-cart_x)
--&gt;
&lt;p&gt;$$
\text{E}(Duration) \approx Amplitude^{0.51} \times \exp(3.05) \&lt;br&gt;
$$
$$
\text{SD}(Duration) \approx 5.53 - 3.56 \exp(-Amplitude) \&lt;br&gt;
$$&lt;/p&gt;
&lt;p&gt;with $E()$ the estimation of the mean and $SD()$ the estimation fo the standard deviation.&lt;/p&gt;
&lt;!-- SD(Duration) = 0.55 + 3.54.Amp
    E(Duration) = Amp^0.51 * exp(3.05)
--&gt;
&lt;h3 id=&#34;implement-a-stochastic-generator&#34;&gt;Implement a Stochastic Generator&lt;/h3&gt;
&lt;p&gt;Let us try to generate data from these equations .&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;getADuration &lt;span style=&#34;color:#5bc4bf&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;function&lt;/span&gt;(amp, n){
  mean.Duration &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; (amp^a) &lt;span style=&#34;color:#5bc4bf&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;exp&lt;/span&gt;(b)
  SD.Duration &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; (sd_ea &lt;span style=&#34;color:#5bc4bf&#34;&gt;+&lt;/span&gt; sd_eb) &lt;span style=&#34;color:#5bc4bf&#34;&gt;-&lt;/span&gt; sd_ea &lt;span style=&#34;color:#5bc4bf&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;exp&lt;/span&gt;(&lt;span style=&#34;color:#5bc4bf&#34;&gt;-&lt;/span&gt;amp)
  &lt;span style=&#34;color:#06b6ef&#34;&gt;return&lt;/span&gt;(&lt;span style=&#34;color:#06b6ef&#34;&gt;rnorm&lt;/span&gt;(&lt;span style=&#34;color:#06b6ef&#34;&gt;length&lt;/span&gt;(mean.Duration)&lt;span style=&#34;color:#5bc4bf&#34;&gt;*&lt;/span&gt;n, mean.Duration, SD.Duration))
}

amp_space &lt;span style=&#34;color:#5bc4bf&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;runif&lt;/span&gt;(&lt;span style=&#34;color:#f99b15&#34;&gt;5000&lt;/span&gt;, min&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;min&lt;/span&gt;(df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;amplitude), max&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;1&lt;/span&gt;)
gen.duration &lt;span style=&#34;color:#5bc4bf&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;getADuration&lt;/span&gt;(amp_space, &lt;span style=&#34;color:#f99b15&#34;&gt;1&lt;/span&gt;)

red_col &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;rgb&lt;/span&gt;(&lt;span style=&#34;color:#f99b15&#34;&gt;200&lt;/span&gt;,&lt;span style=&#34;color:#f99b15&#34;&gt;100&lt;/span&gt;,&lt;span style=&#34;color:#f99b15&#34;&gt;100&lt;/span&gt;,&lt;span style=&#34;color:#f99b15&#34;&gt;50&lt;/span&gt;,maxColorValue&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;255&lt;/span&gt;)
&lt;span style=&#34;color:#06b6ef&#34;&gt;plot&lt;/span&gt;(df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;amplitude, df1&lt;span style=&#34;color:#5bc4bf&#34;&gt;$&lt;/span&gt;duration, ylim&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#f99b15&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#f99b15&#34;&gt;30&lt;/span&gt;), xlim&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#f99b15&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f99b15&#34;&gt;1.2&lt;/span&gt;))
&lt;span style=&#34;color:#06b6ef&#34;&gt;points&lt;/span&gt;(amp_space, gen.duration, ylim &lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#06b6ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#f99b15&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#f99b15&#34;&gt;30&lt;/span&gt;), xlim&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#f99b15&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f99b15&#34;&gt;1.2&lt;/span&gt;), col&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;red_col)
&lt;span style=&#34;color:#06b6ef&#34;&gt;legend&lt;/span&gt;(&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#34;bottomright&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#06b6ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;extracted data&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;model&amp;#39;&lt;/span&gt;), col&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#06b6ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#48b685&#34;&gt;&amp;#39;black&amp;#39;&lt;/span&gt;, red_col), pch&lt;span style=&#34;color:#5bc4bf&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#f99b15&#34;&gt;1&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/research/analyseExtractedData_files/figure-markdown/unnamed-chunk-10-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;The data we generated with the stochastic model (red dots) look pretty close to the real data we extracted from Troncoso et al. 2008.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ve got a pretty cool stochastic generator of saccade durations from a poor quality jpeg! With this generator, we can
predict saccade durations for amplitudes that Troncoso et al.
did not mesure.&lt;/p&gt;
&lt;p&gt;Hope this post was helpful, and see you soon!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Game Release: Catch the Crow</title>
      <link>https://nodragem.github.io/Blog/post/gamedev/catchthecrown_release/</link>
      <pubDate>Fri, 14 Apr 2017 12:43:08 +0100</pubDate>
      
      <guid>https://nodragem.github.io/Blog/post/gamedev/catchthecrown_release/</guid>
      <description>&lt;h2 id=&#34;release-and-then-move-on-&#34;&gt;Release and then move on &amp;hellip;&lt;/h2&gt;
&lt;p&gt;Finally! After 3 years of uneven and chaotic development (partly due to a PhD), it feels like that&amp;rsquo;s the right time to finalize and ship my first video game.&lt;/p&gt;
&lt;figure&gt;
    &lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/catchthecrown_release/prabbit_winning_lowres.gif&#34;
         alt=&#34;How it feels like to ship a game!&#34;/&gt; &lt;figcaption&gt;
            &lt;p&gt;How it feels like to ship a game!&lt;/p&gt;
        &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Catch the Crown is the first game I made with libGDX. It is a multiplayer arena platform game. My pride is that it feels like I am shipping an actual game: it can be run, played and it delivers fun (to my friends at least!). 
You can download it here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Windows, portable version (&lt;a href=&#34;https://github.com/Nodragem/Catch-the-Crown/releases/download/v0.9-alpha/catchthecrown_win32.zip&#34;&gt;zip-file&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Linux, portable version (&lt;a href=&#34;https://github.com/Nodragem/Catch-the-Crown/releases/download/v0.9-alpha/catchthecrown_linux32.zip&#34;&gt;zip-file&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Mac OS, portable version (&lt;a href=&#34;https://github.com/Nodragem/Catch-the-Crown/releases/download/v0.9-alpha/catchthecrown_mac.zip&#34;&gt;zip-file&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Please find more details about customization on the &lt;a href=&#34;https://nodragem.github.io/Blog/Blog/project/catchthecrown/&#34;&gt;Project Page&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;the-story&#34;&gt;The Story&lt;/h2&gt;
&lt;p&gt;I made up most of the story and gameplay with one of my best friends on a 7 hours road trip to Edinburgh :). The basic idea is that in the tribe of the Prabbits - half parrot/half rabbit creatures - four teenagers are undertaking their &amp;ldquo;Coming-of-Age&amp;rdquo; ritual.&lt;/p&gt;
&lt;figure&gt;
    &lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/catchthecrown_release/doing_nothing.gif&#34;
         alt=&#34;Three teenager Prabbits chilling out before the Coming-of-Age ritual&amp;amp;hellip;&#34;/&gt; &lt;figcaption&gt;
            &lt;p&gt;Three teenager Prabbits chilling out before the Coming-of-Age ritual&amp;hellip;&lt;/p&gt;
        &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&#34;the-gameplay&#34;&gt;The Gameplay&lt;/h2&gt;
&lt;p&gt;The Prabbits are spawned on a map where there is one Crown while a timer is running. Once the Crown is picked up by a Prabbit, coins, diamonds, and rubies appear across the level. Only the Prabbit with the Crown can collect them. When collected part of the money goes to the Prabbit&amp;rsquo;s gold chest while the other part goes in the Crown itself.&lt;/p&gt;
&lt;figure&gt;
    &lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/catchthecrown_release/timer.gif&#34; width=&#34;100%&#34;/&gt;
    &lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/catchthecrown_release/catch_crown.gif&#34; width=&#34;100%&#34;/&gt;
    &lt;figcaption&gt;
        Only the Prabbit with the Crown can collect treasures
    &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;A competition starts between Prabbits as everyone wants to catch the Crown and be able to collect gold. When the timer ends, it is the richer Prabbit that wins the turn; players need to win 3 turns to win the tournament and be declared King of the Tournament (see Screenshot1).&lt;/p&gt;
&lt;h2 id=&#34;the-character-actions&#34;&gt;The Character Actions&lt;/h2&gt;
&lt;p&gt;The Prabbits have several ways to hurt each other. They can throw lances, slap each other, pick up another Prabbit and make a lethal throw. To slap someone increases their fatigue (fatigue marks on his head), which will increase the respawning time the next time they die. Time is precious - the longer a player is waiting to respawn, the less they can collect gold or change the outcome of the game.&lt;/p&gt;
&lt;figure&gt;
    &lt;img src=&#34;https://nodragem.github.io/Blog/Blog/img/gamedev/catchthecrown_release/spear_and_slap.gif&#34;
         alt=&#34;Spear, Slap, Trap Combo! I was alone recording, that&amp;amp;rsquo;s why Red is not moving :P&#34;/&gt; &lt;figcaption&gt;
            &lt;p&gt;Spear, Slap, Trap Combo! I was alone recording, that&amp;rsquo;s why Red is not moving :P&lt;/p&gt;
        &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&#34;what-was-not-implemented&#34;&gt;What was not implemented&lt;/h2&gt;
&lt;p&gt;Originally, Catch The Crown was thought to be a cooperative and competitive 2D platform game. A Shaman would have explained the competition rules to the teenager Prabbits. During a round, the players would have a common gold chest in addition to their own. The next level would be unlocked only if the common chest reaches a certain amount of Gold (you can still see this chest in the GUI).&lt;/p&gt;
&lt;p&gt;The levels would have been designed to force cooperative behavior to get more common Gold. Furthermore, the Shaman would summon creatures against which the Prabbits need to fight in cooperation. Thus, to win a tournament would encourage a competitive gameplay, while to unlock a new level would encourage a cooperative gameplay.&lt;/p&gt;
&lt;p&gt;Maybe later I will do a sequel where I will implement more of the stuff I wanted originally. In any case, I will probably come back with new levels for this version of the game. Hope you enjoy the game!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Dynamic Neural Field toolset</title>
      <link>https://nodragem.github.io/Blog/project/dnftool/</link>
      <pubDate>Sun, 12 Mar 2017 20:22:11 +0000</pubDate>
      
      <guid>https://nodragem.github.io/Blog/project/dnftool/</guid>
      <description>&lt;p&gt;Find the project at: &lt;a href=&#34;https://github.com/Nodragem/DynamicNeuralField-RateBased&#34;&gt;https://github.com/Nodragem/DynamicNeuralField-RateBased&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Brain Visual Space toolset</title>
      <link>https://nodragem.github.io/Blog/project/sctovisualtrans/</link>
      <pubDate>Sun, 12 Mar 2017 15:20:11 +0000</pubDate>
      
      <guid>https://nodragem.github.io/Blog/project/sctovisualtrans/</guid>
      <description>&lt;p&gt;Find the project at: &lt;a href=&#34;https://github.com/Nodragem/Model-SCtoVisualSpace&#34;&gt;https://github.com/Nodragem/Model-SCtoVisualSpace&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Eye tracking toolset</title>
      <link>https://nodragem.github.io/Blog/project/eyetracking_toolset/</link>
      <pubDate>Sun, 12 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://nodragem.github.io/Blog/project/eyetracking_toolset/</guid>
      <description>&lt;p&gt;Find the project at: &lt;a href=&#34;https://github.com/Nodragem/Eyetracking-Analysis-tools&#34;&gt;https://github.com/Nodragem/Eyetracking-Analysis-tools&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
